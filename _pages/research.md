---
title: "IMICS Lab - Research"
layout: textlay
excerpt: "IMICS Lab -- Research"
sitemap: false
permalink: /research/
---

# Research

Our research interests lie at the intersection of Machine Learning and Computer Vision with applications in Smart Health, Affective Computing, and Pervasive Computing. We believe that in order to better serve and improve the quality of human lives, it is necessary to understand individual needs along with physiological, behavioral, and environmental factors that can either facilitate or obstruct a higher standard of living and enhanced interaction with an increasingly intelligent environment.

Understanding human needs involves collecting and interpreting large volumes of sensor data, often sensitive, related to health, mental state, and behavioral patterns. Motion tracking, physiological data, and information from everyday activities at home, the clinic, or outdoors are just some examples. Manual analysis of such data can be tedious and prone to errors. Thanks to the theoretical advancements in machine learning over the last few decades, computers have offered a great alternative to handling large amounts of data efficiently. However, there is still a long way to go until these methods can be effectively used in domains such as smart health and pervasive computing.

One of the main reasons for the delay in the adoption of ML in smart health applications is the scarcity of data compared to other applications, such as images and videos available on the web. Despite improvements in hardware and sensor technologies leading to a rapid increase in the volume of data generated from human state and behavior measurements, such data are rarely made publicly available due to privacy concerns and regulations. Moreover, crowdsourcing can be challenging to apply to such types of data for labeling purposes. Therefore, recent significant advances in Deep Learning have had a limited effect on the analysis of human-derived data. Additionally, the heterogeneity in the modalities of human-derived data generated by different types of sensors poses further challenges if the effort combining such modalities towards a collective decision.

Our research efforts have centered on expanding the capabilities of machine learning and computer vision-based algorithms. Our goal is to provide a set of methods and tools that can analyze seemingly unrelated data modalities, detect correlations in information extracted from different sources, and form a common understanding of the underlying patterns. We have adopted an interdisciplinary approach to understanding the causes and effects of human condition and behavior, focusing on multimodal data collection and analysis.

In the following sections, we outline our research contributions, organized into a set of common research themes.


## Research Contributions

### Machine Learning

<img src="/images/respic/biosgan.png" alt="" style="width: 400px; float: right; margin: 10px  0px" />

Our research lab has made significant contributions to the field of machine learning, with a particular focus on applications in healthcare, time-series data, deep learning techniques, and fairness in multi-class classification.

Time-series data analysis has been a main focus. We have proposed Transformer-based time-series Generative Adversarial Networks (GANs), developed tools for reducing label noise in time-series data, and created methods to detect and correct noisy labels. We have also investigated the integration of topological data analysis with deep learning models.
Deep learning techniques, particularly in the context of time-series data, have been a key research direction. We have studied various methods such as Self-attention, LSTM models, and Stateful Training. We also conducted a comparative study between Recurrence and Self-attention against the Transformer for time-series classification.
The lab has demonstrated concern for ethics in AI by addressing bias and fairness. We analyzed bias and inaccuracies in anonymous self-reporting platforms and studied the measurement of bias and fairness in multi-class classification.

Healthcare has been a recurring theme in our work. We have developed systems for personalized fall detection, employing both collaborative edge-cloud computing frameworks and wearables data. Our work has also delved into the utilization of deep learning ensembles on wearables using small datasets. Furthermore, we have shown interest in mental health, exploring virtual reality interventions for student veterans with social anxiety and PTSD, and studying the experiences of student veterans with social anxiety. In the realm of sleep disorders, our lab developed automated detection systems for sleep disorder-related events from polysomnographic data.

The lab's research also spans over to other domains, such as the integration of Virtual Reality and Augmented Reality for first responders' training, IoT middleware, wireless channel visualization using Augmented Reality, and more.

Overall, our lab has showcased a strong commitment to harnessing machine learning for societal benefit, with a particular emphasis on healthcare, while also maintaining a focus on the ethical implications of AI.

### Smart Health and Pervasive Computing

<img src="/images/respic/pervasive_computing.jpg" alt="" style="width: 370px; float: left; margin: 0px  10px" />
The aim of Smart Health research, as envisioned by the National Science Foundation (NSF) and the National Institute of Health (NIH) in the US, is to develop next-generation multidisciplinary science focusing on breakthrough ideas in various areas valuable to health. These include networking, pervasive computing, advanced analytics, sensor integration, privacy and security, modeling of socio-behavioral and cognitive processes, and system and process modeling.

In our research work, we have developed solutions that span the areas of pervasive computing, behavioral and cognitive process analysis, and sensor data fusion and analysis.

### Behavior Modeling and Activity Recognition
<img src="/images/respic/exercise_motion_tracking.png" alt="" style="width: 340px; float: right; margin: 10px  0px" />

Behavior modeling and activity recognition are valuable areas that can be harnessed by various smart health applications. Our research group has been keenly focused on developing sophisticated algorithms for human motion analysis, contributing to this vital domain of study.

We have applied these algorithms for a diverse array of applications. For instance, we have used motion analysis for the detection of abnormal behavior, a critical component for ensuring the safety and well-being of individuals in healthcare settings. Also, we've utilized it in video and smartwatch-based fall detection systems, providing an essential tool for monitoring the elderly or those at risk of falls.

A significant part of our work has been the enhancement of physical therapy through human motion tracking. We've innovatively utilized our algorithms to model the movements of a human interacting with robotic devices such as a robotic arm or an omnidirectional treadmill.

In the realm of Human-Computer Interaction (HCI) and assistive living applications, another aspect of behavior modeling that our research group has delved into is eye tracking and attention modeling. Our contributions in this area include a publicly available dataset for assistive eye tracking applications. Moreover, we have explored the use of this technology in attention modeling for game-based rehabilitation therapy.

We are excited about the potential these research areas hold for improving human lives. By continually expanding and refining our machine learning and computer vision-based algorithms, we aim to push the boundaries of what's achievable in behavior modeling and activity recognition.


### Sleep Monitoring

<img src="/images/respic/sleep_monitoring.png" alt="" style="width: 420px; float: left; margin: 0px  10px" />
The importance of good quality sleep for overall health and well-being cannot be overstated. Recognizing this, one of the primary objectives of our research has been to devise innovative solutions for monitoring sleep patterns.

Our initial efforts in sleep monitoring were focused on developing motion-based, unobtrusive, at-home sleep quality tracking methods. The intention behind this approach was to facilitate the everyday person in keeping tabs on their sleep quality without the need for professional or clinical involvement.

Traditional sleep studies, however, involve the collection and analysis of a multitude of physiological biosignals by sleep experts. To achieve at-home sleep monitoring of similar quality to sleep labs, automatic analysis of physiological data is required. To address this, we expanded our research efforts by developing machine learning-based methods for denoising and analyzing physiological sleep data.

These advancements have proven invaluable for automatic sleep disorder detection. This automated detection approach can offer an early warning system for people at risk of developing serious health issues tied to poor sleep quality.

Moving forward, we hope to further refine these processes and introduce even more efficient and accurate methods of sleep monitoring, making it easier for individuals to understand and improve their sleep patterns, and ultimately, their overall health.


### Virtual Reality, Affective Computing, and Physiological Biosignal Analysis

<img src="/images/respic/emotion_recogntition.png" alt="" style="width: 440px; float: right; margin: 10px  0px" />

Our research group's interests extend to the dynamic intersection of Virtual Reality (VR), Affective Computing, and Physiological Biosignal Analysis. We've been privileged to work alongside colleagues from the social sciences, exploring the profound potentials of these combined fields.

Specifically, our focus has been on developing Virtual Reality (VR) environments for therapeutic intervention, a novel approach in digital healthcare. Our ongoing project involves aiding war veterans in overcoming social anxiety symptoms, a common but often debilitating consequence of traumatic experiences. By leveraging VR's immersive capabilities, we can create simulated social scenarios that offer a safe and controlled space for veterans to gradually confront and manage their anxieties.

An integral part of this therapeutic process is physiological biosignal analysis. By tracking emotional responses to the VR stimulus through biosignals, we can gain valuable insights into an individual's emotional state, allowing us to adjust the therapy accordingly. Our experimental studies on emotion recognition from physiological biosignal data collected by our team have demonstrated the feasibility of such a task, paving the way for more personalized and effective therapeutic interventions.

In the future, we plan to extend this line of research, harnessing the potential of VR and affective computing to address a wider range of mental health issues. Our goal is to continually refine our methods of analysis and interpretation of physiological biosignals to improve the effectiveness of VR-based therapies, contributing to advancements in mental health treatment.




### Other Pervasive Computing applications

<img src="/images/respic/assistive_env.png" alt="" style="width: 250px; float: left; margin: 0px  10px" />
Beyond the scope of our aforementioned research themes, we also have a diverse portfolio of contributions to various other pervasive computing applications. These projects echo our mission of using technology to solve real-world problems and improve lives.

One such project involved developing an evaluation framework and Quality of Service (QoS) metrics for pervasive computing applications. These tools can be invaluable in optimizing performance and ensuring the reliable and effective delivery of services.

Another initiative we are proud of is the development of a smart medicine drawer solution. This smart drawer aims to simplify medication management, reducing errors and enhancing adherence to prescribed medication schedules.

Recognizing the importance of the Internet of Things (IoT) in modern computing applications, we conducted an extensive survey of IoT Middleware solutions. Our findings contribute to the understanding and further development of this crucial technology.

Finally, we undertook a study of extending home-based assistive living applications to a larger, city-wide scale. The implications of this work are exciting, potentially enabling more expansive and integrated care networks that can better support aging populations.

Our team continues to explore new horizons in pervasive computing, motivated by our commitment to making technology accessible, beneficial, and meaningful to as many people as possible.

### ... and more.
