---
title: "IMICS Lab - Research"
layout: textlay
excerpt: "IMICS Lab -- Research"
sitemap: false
permalink: /research/
---

# Research

Our research interests lie at the intersection of Machine Learning and Computer Vision, focusing on Smart Health, Affective Computing, and Pervasive Computing. We believe that in order to better serve and improve the quality of human lives, it's necessary to understand individual needs along with physiological, behavioral, and environmental factors that can either facilitate or obstruct a higher standard of living and enhanced interaction with an increasingly intelligent environment.

Understanding human needs involves collecting and interpreting large volumes of sensor data, often sensitive, related to health, mental state, and behavioral patterns. Motion tracking, physiological data, and information from everyday activities at home, the clinic, or outdoors are just some examples. Manual analysis of such data can be tedious and prone to errors. Thanks to the theoretical advancements in machine learning over the last few decades, computers have offered a great alternative in handling large amounts of data efficiently. However, there is still a long way to go until these methods can be effectively used in domains such as smart health and pervasive computing.

One of the main reasons for the delay in the adoption of ML in smart health applications is the scarcity of data compared to other applications, such as images and videos available on the web. Despite improvements in hardware and sensor technologies leading to a rapid increase in the volume of data generated from human state and behavior measurements, such data are rarely made publicly available due to privacy concerns and regulations. Moreover, crowdsourcing can be challenging to apply to such types of data for labeling purposes. Therefore, recent significant advances in Deep Learning have had a limited effect on the analysis of human-derived data. Additionally, the heterogeneity in the modalities of human-derived data generated by different types of sensors poses further challenges if the effort combining such modalities towards a collective decision.

Our research efforts have centered on expanding the capabilities of machine learning and computer vision-based algorithms. Our goal is to provide a set of methods and tools that can analyze seemingly unrelated data modalities, detect correlations in information extracted from different sources, and form a common understanding of the underlying patterns. We have adopted an interdisciplinary approach to understand the causes and effects of human condition and behavior, focusing on multimodal data collection and analysis.

In the following sections, we outline our research contributions, organized into a set of common research themes.


## Research Contributions

### Smart Health and Pervasive Computing
The aim of Smart Health research, as envisioned by the National Science Foundation (NSF) and the National Institute of Health (NIH) in the US, is to develop next-generation multidisciplinary science focusing on breakthrough ideas in various areas valuable to health. These include networking, pervasive computing, advanced analytics, sensor integration, privacy and security, modeling of socio-behavioral and cognitive processes, and system and process modeling.

In our research work, we have developed solutions that span the areas of pervasive computing, behavioral and cognitive process analysis, and sensor data fusion and analysis.

### Behavior Modeling and Activity Recognition
Behavior modeling and activity recognition are valuable areas that can be harnessed by various smart health applications. Our research group has been keenly focused on developing sophisticated algorithms for human motion analysis, contributing to this vital domain of study.

We have applied these algorithms for a diverse array of applications. For instance, we have used motion analysis for the detection of abnormal behavior, a critical component for ensuring the safety and well-being of individuals in healthcare settings. Also, we've utilized it in video and smartwatch-based fall detection systems, providing an essential tool for monitoring the elderly or those at risk of falls.

A significant part of our work has been the enhancement of physical therapy through human motion tracking. We've innovatively utilized our algorithms to model the movements of a human interacting with robotic devices such as a robotic arm or an omnidirectional treadmill.

In the realm of Human-Computer Interaction (HCI) and assistive living applications, another aspect of behavior modeling that our research group has delved into is eye tracking and attention modeling. Our contributions in this area include a publicly available dataset for assistive eye tracking applications. Moreover, we have explored the use of this technology in attention modeling for game-based rehabilitation therapy.

We are excited about the potential these research areas hold for improving human lives. By continually expanding and refining our machine learning and computer vision-based algorithms, we aim to push the boundaries of what's achievable in behavior modeling and activity recognition.


### Sleep Monitoring

The importance of good quality sleep for overall health and well-being cannot be overstated. Recognizing this, one of the primary objectives of our research has been to devise innovative solutions for monitoring sleep patterns.

Our initial efforts in sleep monitoring were focused on developing motion-based, unobtrusive, at-home sleep quality tracking methods. The intention behind this approach was to facilitate the everyday person in keeping tabs on their sleep quality without the need for professional or clinical involvement.

Traditional sleep studies, however, involve the collection and analysis of a multitude of physiological biosignals by sleep experts. To achieve at-home sleep monitoring of similar quality to sleep labs, automatic analysis of physiological data is required. To address this, we expanded our research efforts by developing machine learning-based methods for denoising and analyzing physiological sleep data.

These advancements have proven invaluable for automatic sleep disorder detection. This automated detection approach can offer an early warning system for people at risk of developing serious health issues tied to poor sleep quality.

Moving forward, we hope to further refine these processes and introduce even more efficient and accurate methods of sleep monitoring, making it easier for individuals to understand and improve their sleep patterns, and ultimately, their overall health.


### Virtual Reality, Affective Computing, and Physiological Biosignal Analysis

Our research group's interests extend to the dynamic intersection of Virtual Reality (VR), Affective Computing, and Physiological Biosignal Analysis. We've been privileged to work alongside colleagues from the social sciences, exploring the profound potentials of these combined fields.

Specifically, our focus has been on developing Virtual Reality (VR) environments for therapeutic intervention, a novel approach in digital healthcare. Our ongoing project involves aiding war veterans in overcoming social anxiety symptoms, a common but often debilitating consequence of traumatic experiences. By leveraging VR's immersive capabilities, we can create simulated social scenarios that offer a safe and controlled space for veterans to gradually confront and manage their anxieties.

An integral part of this therapeutic process is physiological biosignal analysis. By tracking emotional responses to the VR stimulus through biosignals, we can gain valuable insights into an individual's emotional state, allowing us to adjust the therapy accordingly. Our experimental studies on emotion recognition from physiological biosignal data collected by our team have demonstrated the feasibility of such a task, paving the way for more personalized and effective therapeutic interventions.

In the future, we plan to extend this line of research, harnessing the potential of VR and affective computing to address a wider range of mental health issues. Our goal is to continually refine our methods of analysis and interpretation of physiological biosignals to improve the effectiveness of VR-based therapies, contributing to advancements in mental health treatment.




### Other Pervasive Computing applications

Beyond the scope of our aforementioned research themes, we also have a diverse portfolio of contributions to various other pervasive computing applications. These projects echo our mission of using technology to solve real-world problems and improve lives.

One such project involved developing an evaluation framework and Quality of Service (QoS) metrics for pervasive computing applications. These tools can be invaluable in optimizing performance and ensuring the reliable and effective delivery of services.

Another initiative we are proud of is the development of a smart medicine drawer solution. This smart drawer aims to simplify medication management, reducing errors and enhancing adherence to prescribed medication schedules.

Recognizing the importance of the Internet of Things (IoT) in modern computing applications, we conducted an extensive survey of IoT Middleware solutions. Our findings contribute to the understanding and further development of this crucial technology.

Finally, we undertook a study of extending home-based assistive living applications to a larger, city-wide scale. The implications of this work are exciting, potentially enabling more expansive and integrated care networks that can better support aging populations.

Our team continues to explore new horizons in pervasive computing, motivated by our commitment to making technology accessible, beneficial, and meaningful to as many people as possible.



### Contributions to Machine Learning
Several applications mentioned in the section above required us to extend the current theoretical state-of-the-art in machine learning solutions and algorithms.

One of the main steps in machine learning applications is feature selection. In our work, we developed a novel feature selection method based on sparsity-inducing norms, which was shown to perform better than the best existing feature selection algorithms in multi-class classification problems involving cancer detection. This method is general enough to apply to any feature selection application.

In our studies, we presented a filter-and-refine approach to dealing with very high dimensionality and tackled the problem of multi-modal feature fusion, when the number of features of different modalities is highly imbalanced.

To address the need for a computationally light-weight solution for activity recognition, we developed two correlation analysis-based algorithms for activity classification.

We also developed a method for sensor placement to achieve optimal area coverage given the amount of available resources. The solution models sensors as independent agents which coordinate using factor graphs. To solve the coordination problem, we extended the Max-Sum algorithm for decentralized coordination.

Finally, in one of our earlier works in machine learning research, we analyzed the theoretical properties of the various versions of Naive Bayes classifiers and evaluated their performance in spam email filtering applications.

We continually strive to push the boundaries of our understanding and applications of machine learning, and look forward to making new discoveries and advancements that will impact the field.

### ... and more.
