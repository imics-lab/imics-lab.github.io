---
title: "IMICS Lab - Research"
layout: textlay
excerpt: "IMICS Lab -- Research"
sitemap: false
permalink: /research/
---

# Research

Our lab explores the nexus of Machine Learning and Computer Vision, focusing on applications in Smart Health, Affective Computing, and Pervasive Computing. We aim to enhance the quality of human life through understanding individual needs and the physiological, behavioral, and environmental factors influencing them.

The crux of our work lies in collating and interpreting substantial amounts of sensor data related to health, mental state, and behavioral patterns. We employ machine learning to efficiently handle these data, sidestepping the pitfalls of manual analysis. However, the journey towards leveraging these methodologies in areas such as smart health and pervasive computing is ongoing.

The scarcity of data for smart health applications compared to other domains forms a major roadblock. Despite the surge in data from human state and behavioral measurements, privacy concerns and regulations limit their public availability. The heterogeneity of this human-derived data further complicates their consolidation for a comprehensive understanding.

Our research strategy aims to enhance machine learning and computer vision-based algorithms to analyze diverse data modalities and detect underlying patterns. We adopt an interdisciplinary approach, emphasizing multimodal data collection and analysis.

Below, we present our research contributions organized into key research themes.

## Research Contributions

### Machine Learning

<img src="/images/respic/biosgan.png" alt="" style="width: 400px; float: right; margin: 10px  0px" />
Our lab has significantly contributed to machine learning, concentrating on applications in healthcare, time-series data, deep learning techniques, and fairness in multi-class classification.

We've developed Transformer-based time-series Generative Adversarial Networks (GANs), tools for reducing label noise in time-series data, and methods to detect and correct noisy labels. Deep learning techniques, particularly for time-series data, form our primary research direction, with studies on Self-attention, LSTM models, Stateful Training, and more.

Our focus on ethics in AI led us to study bias and fairness in anonymous self-reporting platforms and multi-class classification. In healthcare, we've developed personalized fall detection systems and methods for mental health support, among others.

Our other research domains include Virtual Reality and Augmented Reality for first responder training, IoT middleware, and wireless channel visualization.

### Smart Health and Pervasive Computing

<img src="/images/respic/pervasive_computing.jpg" alt="" style="width: 370px; float: left; margin: 0px  10px" />
In alignment with the vision of the NSF and NIH, we aim to develop cutting-edge, multidisciplinary science in areas beneficial to health, such as pervasive computing, advanced analytics, and sensor integration.

### Behavior Modeling and Activity Recognition

<img src="/images/respic/exercise_motion_tracking.png" alt="" style="width: 340px; float: right; margin: 10px  0px" />
Our group has been instrumental in developing sophisticated algorithms for human motion analysis. We've leveraged these for applications such as abnormal behavior detection, fall detection systems, physical therapy enhancement, and attention modeling in game-based rehabilitation therapy.

### Sleep Monitoring

<img src="/images/respic/sleep_monitoring.png" alt="" style="width: 420px; float: left; margin: 0px  10px" />
Recognizing sleep's importance for overall health, we've devised solutions for monitoring sleep patterns. Our efforts include developing unobtrusive sleep quality tracking methods and machine learning-based approaches for physiological sleep data analysis and sleep disorder detection.

### Virtual Reality, Affective Computing, and Physiological Biosignal Analysis

<img src="/images/respic/emotion_recogntition.png" alt="" style="width: 440px; float: right; margin: 10px  0px" />

Our interests extend to the fusion of Virtual Reality (VR), Affective Computing, and Physiological Biosignal Analysis. We've collaborated with social science peers to exploit these fields' potentials.

Our key focus is developing VR environments for therapeutic intervention, with ongoing projects designed to help war veterans overcome social anxiety symptoms. By analyzing physiological biosignals, we glean insights into individuals' emotional responses, enabling us to personalize therapy accordingly.

In the future, we aim to broaden this research, leveraging VR and affective computing to address a variety of mental health issues. Our objective is to consistently enhance our analysis and interpretation of physiological biosignals to improve VR-based therapies' effectiveness, contributing to mental health treatment advancements.

### Other Pervasive Computing applications

<img src="/images/respic/pervasive_computing2.png" alt="" style="width: 420px; float: left; margin: 0px 10px" />
Apart from the domains outlined above, our research also encompasses a diverse set of Pervasive Computing applications. Our work in this area is guided by the potential of these applications to revolutionize the interaction between humans and their environment. Detailed descriptions of our contributions to these domains will follow in subsequent sections. Stay tuned for more updates on our ongoing projects and exciting new initiatives.

### ... and more.
